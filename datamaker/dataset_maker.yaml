defaults:
  - _self_

# how many sentences to include in the dataset
splits:
  train: 10000
  test:  10000

# mapping between huggingface dataset name and the approximate proportion of sentences to pull from that dataset
# values must sum to 1.
datasets:
  wikipedia: 0.68
  bookcorpus: 0.32

dataset_args:
  wikipedia: [20200501.en]
  bookcorpus: []
  
dataset_kwargs:
  wikipedia: {}
  bookcorpus: {}

# what to name the dataset
# default is the key=value for each k,v in ${datasets}, joined with '-'.
name: ${namer:${datasets}}
  
hydra:
  run:
    dir: datasets/${name}-${now:%Y-%m-%d_%H-%M-%S}
  sweep:
    dir: datasets
    subdir: ${name}-${now:%Y-%m-%d_%H-%M-%S}
